{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bI28jbJmD4Fn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zos6aKlgEC1k",
    "outputId": "5260fddc-7338-4bfd-8b3e-3caca146467f"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import scikeras\n",
    "except ImportError:\n",
    "    !python -m pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g3WCSTvcEKoQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "JKBX0ea0EaAt",
    "outputId": "53924eff-e81f-42a0-b0a3-a1d69a8293ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7801</th>\n",
       "      <td>7802</td>\n",
       "      <td>15798844</td>\n",
       "      <td>Chijindum</td>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>128914.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191746.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7542</th>\n",
       "      <td>7543</td>\n",
       "      <td>15768777</td>\n",
       "      <td>Wang</td>\n",
       "      <td>507</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60688.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>4213</td>\n",
       "      <td>15773512</td>\n",
       "      <td>Bischof</td>\n",
       "      <td>627</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>194313.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8283</th>\n",
       "      <td>8284</td>\n",
       "      <td>15754569</td>\n",
       "      <td>Pagnotto</td>\n",
       "      <td>664</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56562.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>6624</td>\n",
       "      <td>15610753</td>\n",
       "      <td>Cremonesi</td>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>104367.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29937.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>5795</td>\n",
       "      <td>15694125</td>\n",
       "      <td>McElhone</td>\n",
       "      <td>669</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56875.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>826</td>\n",
       "      <td>15660602</td>\n",
       "      <td>Ch'eng</td>\n",
       "      <td>464</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>164284.72</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3710.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>3557</td>\n",
       "      <td>15651823</td>\n",
       "      <td>Nkemjika</td>\n",
       "      <td>590</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>147751.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88206.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>9122</td>\n",
       "      <td>15693526</td>\n",
       "      <td>Ku</td>\n",
       "      <td>618</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119059.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>203</td>\n",
       "      <td>15600974</td>\n",
       "      <td>He</td>\n",
       "      <td>516</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146145.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "7801       7802    15798844  Chijindum          678    France    Male   54   \n",
       "7542       7543    15768777       Wang          507     Spain  Female   34   \n",
       "4212       4213    15773512    Bischof          627     Spain  Female   25   \n",
       "8283       8284    15754569   Pagnotto          664    France    Male   57   \n",
       "6623       6624    15610753  Cremonesi          581    France    Male   28   \n",
       "5794       5795    15694125   McElhone          669    France    Male   57   \n",
       "825         826    15660602     Ch'eng          464   Germany    Male   33   \n",
       "3556       3557    15651823   Nkemjika          590    France  Female   60   \n",
       "9121       9122    15693526         Ku          618    France  Female   40   \n",
       "202         203    15600974         He          516     Spain    Male   50   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "7801       7  128914.97              1          0               0   \n",
       "7542       4       0.00              2          1               1   \n",
       "4212       4       0.00              1          1               1   \n",
       "8283       1       0.00              2          1               1   \n",
       "6623       3  104367.50              1          1               1   \n",
       "5794       5       0.00              2          1               1   \n",
       "825        8  164284.72              2          1               1   \n",
       "3556       6  147751.75              1          1               0   \n",
       "9121       0       0.00              1          1               0   \n",
       "202        5       0.00              1          0               1   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "7801        191746.23       1  \n",
       "7542         60688.38       0  \n",
       "4212        194313.93       0  \n",
       "8283         56562.57       0  \n",
       "6623         29937.75       0  \n",
       "5794         56875.76       0  \n",
       "825           3710.34       0  \n",
       "3556         88206.04       1  \n",
       "9121        119059.13       0  \n",
       "202         146145.93       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hJdOCsKvEhmi"
   },
   "outputs": [],
   "source": [
    "dataset = data.copy()\n",
    "\n",
    "del dataset['RowNumber']\n",
    "\n",
    "del dataset['Surname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cch-Naq0EnQz"
   },
   "outputs": [],
   "source": [
    "del dataset['CustomerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Geography', 'Gender']:\n",
    "    dataset[column] = dataset[column].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0       0   42       2       0.00              1   \n",
       "1          608          2       0   41       1   83807.86              1   \n",
       "2          502          0       0   42       8  159660.80              3   \n",
       "3          699          0       0   39       1       0.00              2   \n",
       "4          850          2       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "42MkNpVhEul9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bemntGhnE4Gg"
   },
   "outputs": [],
   "source": [
    "points = dataset['Exited']\n",
    "values = dataset.drop(['Exited'], axis = 1)\n",
    "\n",
    "train_points, test_points, train_values, test_values = train_test_split(values, points, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhWRiyXnE7xW",
    "outputId": "9408fda5-83fd-4f47-c484-0cd29c4436d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5266 - loss: 3628.3423 - val_accuracy: 0.2005 - val_loss: 59.2151\n",
      "Epoch 2/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6638 - loss: 35.3758 - val_accuracy: 0.2170 - val_loss: 21.9514\n",
      "Epoch 3/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6637 - loss: 24.6576 - val_accuracy: 0.8055 - val_loss: 25.6102\n",
      "Epoch 4/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6810 - loss: 25.3016 - val_accuracy: 0.5145 - val_loss: 8.3302\n",
      "Epoch 5/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6743 - loss: 24.0227 - val_accuracy: 0.8055 - val_loss: 19.8434\n",
      "Epoch 6/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6785 - loss: 35.9862 - val_accuracy: 0.8055 - val_loss: 44.0145\n",
      "Epoch 7/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6847 - loss: 26.9305 - val_accuracy: 0.7630 - val_loss: 19.9443\n",
      "Epoch 8/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6704 - loss: 25.2986 - val_accuracy: 0.5635 - val_loss: 18.5225\n",
      "Epoch 9/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6837 - loss: 18.9051 - val_accuracy: 0.8055 - val_loss: 20.8430\n",
      "Epoch 10/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 21.0019 - val_accuracy: 0.5345 - val_loss: 7.2141\n",
      "Test-Accuracy: 0.6831250190734863\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(11, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(15, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "results = model.fit(\n",
    " train_points, train_values,\n",
    " epochs= 10,\n",
    " batch_size = 10,\n",
    " validation_data = (test_points, test_values)\n",
    ")\n",
    "print(\"Test-Accuracy:\", np.max(results.history[\"accuracy\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qt1sFOM5FKIe",
    "outputId": "e6023e2f-fa93-4cbc-edab-4a15982f9fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7748 - loss: 12452.4512 - val_accuracy: 0.7615 - val_loss: 2765.7976\n",
      "Epoch 2/5\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6736 - loss: 1727.7412 - val_accuracy: 0.7555 - val_loss: 216.1698\n",
      "Epoch 3/5\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6860 - loss: 206.5387 - val_accuracy: 0.8055 - val_loss: 154.8853\n",
      "Epoch 4/5\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6851 - loss: 101.8526 - val_accuracy: 0.6475 - val_loss: 54.4050\n",
      "Epoch 5/5\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6828 - loss: 75.4721 - val_accuracy: 0.7485 - val_loss: 79.3372\n",
      "Test-Accuracy: 0.7179999947547913\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(11, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(15, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "results = model.fit(\n",
    " train_points, train_values,\n",
    " epochs= 5,\n",
    " batch_size = 100,\n",
    " validation_data = (test_points, test_values)\n",
    ")\n",
    "print(\"Test-Accuracy:\", np.max(results.history[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xq7fejl4FNBm",
    "outputId": "45f48dc7-2bcc-451c-bf2d-2270fb56ffae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2843 - loss: 10318.6367 - val_accuracy: 0.3605 - val_loss: 142.1801\n",
      "Epoch 2/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6170 - loss: 96.0880 - val_accuracy: 0.6990 - val_loss: 41.2516\n",
      "Epoch 3/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 38.0866 - val_accuracy: 0.6485 - val_loss: 24.6743\n",
      "Epoch 4/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6330 - loss: 24.2493 - val_accuracy: 0.7850 - val_loss: 36.3844\n",
      "Epoch 5/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6904 - loss: 36.1506 - val_accuracy: 0.6015 - val_loss: 13.3949\n",
      "Epoch 6/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6759 - loss: 30.4926 - val_accuracy: 0.7715 - val_loss: 12.6635\n",
      "Epoch 7/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6671 - loss: 25.7469 - val_accuracy: 0.7985 - val_loss: 42.9127\n",
      "Epoch 8/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6928 - loss: 28.9090 - val_accuracy: 0.5475 - val_loss: 15.7463\n",
      "Epoch 9/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6699 - loss: 21.7083 - val_accuracy: 0.4340 - val_loss: 32.7058\n",
      "Epoch 10/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6659 - loss: 17.7401 - val_accuracy: 0.7790 - val_loss: 22.6823\n",
      "Test-Accuracy: 0.6825000047683716\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(11, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(15, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "results = model.fit(\n",
    " train_points, train_values,\n",
    " epochs= 10,\n",
    " batch_size = 100,\n",
    " validation_data = (test_points, test_values)\n",
    ")\n",
    "print(\"Test-Accuracy:\", np.max(results.history[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-QOnSUdFTrJ",
    "outputId": "9662df9d-cd50-43e3-8c27-39c4d3de0460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 552.3350 - val_accuracy: 0.4740 - val_loss: 124.7627\n",
      "Epoch 2/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6763 - loss: 80.0034 - val_accuracy: 0.7980 - val_loss: 92.3069\n",
      "Epoch 3/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6773 - loss: 57.6369 - val_accuracy: 0.7630 - val_loss: 33.9198\n",
      "Epoch 4/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6813 - loss: 58.3411 - val_accuracy: 0.8035 - val_loss: 43.1998\n",
      "Epoch 5/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6860 - loss: 46.1231 - val_accuracy: 0.5995 - val_loss: 23.9638\n",
      "Epoch 6/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6764 - loss: 53.2200 - val_accuracy: 0.8010 - val_loss: 81.3521\n",
      "Epoch 7/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6842 - loss: 46.6260 - val_accuracy: 0.8005 - val_loss: 38.3155\n",
      "Epoch 8/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 41.3883 - val_accuracy: 0.8005 - val_loss: 30.1133\n",
      "Epoch 9/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6758 - loss: 55.7217 - val_accuracy: 0.2215 - val_loss: 69.6938\n",
      "Epoch 10/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6800 - loss: 37.7806 - val_accuracy: 0.7530 - val_loss: 24.9826\n",
      "Epoch 11/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6785 - loss: 43.8472 - val_accuracy: 0.7115 - val_loss: 4.5221\n",
      "Epoch 12/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6803 - loss: 29.9032 - val_accuracy: 0.2945 - val_loss: 23.3074\n",
      "Epoch 13/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6836 - loss: 24.3321 - val_accuracy: 0.8050 - val_loss: 33.5007\n",
      "Epoch 14/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6702 - loss: 31.7904 - val_accuracy: 0.8055 - val_loss: 40.7958\n",
      "Epoch 15/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6758 - loss: 25.1370 - val_accuracy: 0.4910 - val_loss: 34.1226\n",
      "Epoch 16/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6904 - loss: 19.7956 - val_accuracy: 0.7835 - val_loss: 4.1332\n",
      "Epoch 17/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6909 - loss: 16.4619 - val_accuracy: 0.4455 - val_loss: 25.5387\n",
      "Epoch 18/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6635 - loss: 17.2127 - val_accuracy: 0.2920 - val_loss: 5.9639\n",
      "Epoch 19/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6793 - loss: 14.2167 - val_accuracy: 0.8050 - val_loss: 22.6615\n",
      "Epoch 20/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6810 - loss: 13.1896 - val_accuracy: 0.7815 - val_loss: 1.8487\n",
      "Epoch 21/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6803 - loss: 14.0021 - val_accuracy: 0.8045 - val_loss: 20.9543\n",
      "Epoch 22/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6870 - loss: 11.5553 - val_accuracy: 0.8040 - val_loss: 18.0655\n",
      "Epoch 23/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6862 - loss: 13.2364 - val_accuracy: 0.8040 - val_loss: 7.9351\n",
      "Epoch 24/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6920 - loss: 7.4868 - val_accuracy: 0.8060 - val_loss: 16.5203\n",
      "Epoch 25/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6703 - loss: 10.3942 - val_accuracy: 0.7895 - val_loss: 10.3613\n",
      "Epoch 26/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6849 - loss: 7.2630 - val_accuracy: 0.7880 - val_loss: 1.2569\n",
      "Epoch 27/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6922 - loss: 6.0574 - val_accuracy: 0.8020 - val_loss: 4.0221\n",
      "Epoch 28/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6835 - loss: 5.7567 - val_accuracy: 0.8000 - val_loss: 4.8723\n",
      "Epoch 29/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6931 - loss: 4.2661 - val_accuracy: 0.8055 - val_loss: 11.8127\n",
      "Epoch 30/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6876 - loss: 4.1857 - val_accuracy: 0.3930 - val_loss: 2.6795\n",
      "Test-Accuracy: 0.690500020980835\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(11, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(15, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(8, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "results = model.fit(\n",
    " train_points, train_values,\n",
    " epochs= 30,\n",
    " batch_size = 10,\n",
    " validation_data = (test_points, test_values)\n",
    ")\n",
    "print(\"Test-Accuracy:\", np.max(results.history[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFBoVOegFoKv",
    "outputId": "f675e2fe-f490-4444-810e-fa6d124d83be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6537 - loss: 240.3270 - val_accuracy: 0.7770 - val_loss: 5.7974\n",
      "Epoch 2/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7141 - loss: 14.4944 - val_accuracy: 0.8055 - val_loss: 12.2375\n",
      "Epoch 3/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 7.0075 - val_accuracy: 0.7840 - val_loss: 1.6370\n",
      "Epoch 4/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7725 - loss: 2.9384 - val_accuracy: 0.7850 - val_loss: 0.7305\n",
      "Epoch 5/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7929 - loss: 0.5495 - val_accuracy: 0.8055 - val_loss: 0.4942\n",
      "Epoch 6/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.5051 - val_accuracy: 0.8055 - val_loss: 0.4933\n",
      "Epoch 7/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.5162 - val_accuracy: 0.8055 - val_loss: 0.4930\n",
      "Epoch 8/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.5046 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 9/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.5175 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Epoch 10/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7912 - loss: 0.5151 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Epoch 11/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.5163 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Epoch 12/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.5189 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Epoch 13/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7930 - loss: 0.5119 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Epoch 14/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.5084 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 15/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.5103 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Epoch 16/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7810 - loss: 0.5279 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Epoch 17/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.5093 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Epoch 18/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.5009 - val_accuracy: 0.8055 - val_loss: 0.4930\n",
      "Epoch 19/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.5112 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 20/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7964 - loss: 0.5071 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 21/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7875 - loss: 0.5175 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Epoch 22/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4997 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 23/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7945 - loss: 0.5079 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 24/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.5107 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 25/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7956 - loss: 0.5069 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 26/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.5062 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 27/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7962 - loss: 0.5055 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 28/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 0.5087 - val_accuracy: 0.8055 - val_loss: 0.4929\n",
      "Epoch 29/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.5071 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Epoch 30/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.5129 - val_accuracy: 0.8055 - val_loss: 0.4928\n",
      "Test-Accuracy: 0.7940000295639038\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(11, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(10, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(10, activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"RMSprop\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "results = model.fit(\n",
    " train_points, train_values,\n",
    " epochs= 30,\n",
    " batch_size = 10,\n",
    " validation_data = (test_points, test_values)\n",
    ")\n",
    "print(\"Test-Accuracy:\", np.max(results.history[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZXsMljmGqCN",
    "outputId": "871c2c61-bcef-4ba9-bd54-8bcd1af908c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6228 - loss: 2221.6555 - val_accuracy: 0.5840 - val_loss: 73.8701\n",
      "Epoch 2/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6803 - loss: 101.7506 - val_accuracy: 0.5425 - val_loss: 61.0571\n",
      "Epoch 3/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6711 - loss: 90.1274 - val_accuracy: 0.8055 - val_loss: 105.3475\n",
      "Epoch 4/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6922 - loss: 75.2828 - val_accuracy: 0.7775 - val_loss: 72.5630\n",
      "Epoch 5/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6769 - loss: 77.4317 - val_accuracy: 0.5495 - val_loss: 53.3947\n",
      "Epoch 6/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6754 - loss: 48.9091 - val_accuracy: 0.8055 - val_loss: 215.3472\n",
      "Epoch 7/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6823 - loss: 63.8062 - val_accuracy: 0.7685 - val_loss: 12.1417\n",
      "Epoch 8/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6722 - loss: 55.8193 - val_accuracy: 0.7835 - val_loss: 11.1864\n",
      "Epoch 9/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6848 - loss: 29.9299 - val_accuracy: 0.8035 - val_loss: 19.9281\n",
      "Epoch 10/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6806 - loss: 40.8060 - val_accuracy: 0.8025 - val_loss: 19.0769\n",
      "Epoch 11/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6721 - loss: 35.9440 - val_accuracy: 0.6370 - val_loss: 26.0814\n",
      "Epoch 12/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6699 - loss: 29.8704 - val_accuracy: 0.8005 - val_loss: 7.7894\n",
      "Epoch 13/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6863 - loss: 22.2182 - val_accuracy: 0.8005 - val_loss: 49.9920\n",
      "Epoch 14/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6704 - loss: 23.6874 - val_accuracy: 0.5345 - val_loss: 19.8738\n",
      "Epoch 15/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6619 - loss: 15.2261 - val_accuracy: 0.5395 - val_loss: 21.7654\n",
      "Epoch 16/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6682 - loss: 16.7469 - val_accuracy: 0.4845 - val_loss: 6.7095\n",
      "Epoch 17/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6709 - loss: 9.2201 - val_accuracy: 0.7330 - val_loss: 7.7894\n",
      "Epoch 18/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 10.0228 - val_accuracy: 0.7110 - val_loss: 18.0066\n",
      "Epoch 19/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6782 - loss: 7.2781 - val_accuracy: 0.4955 - val_loss: 1.7916\n",
      "Epoch 20/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7268 - loss: 1.4395 - val_accuracy: 0.5835 - val_loss: 1.3293\n",
      "Epoch 21/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 1.1209 - val_accuracy: 0.8030 - val_loss: 1.0176\n",
      "Epoch 22/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7617 - loss: 0.8044 - val_accuracy: 0.8055 - val_loss: 0.5176\n",
      "Epoch 23/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.5617 - val_accuracy: 0.7865 - val_loss: 0.5243\n",
      "Epoch 24/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.9555 - val_accuracy: 0.8055 - val_loss: 0.4895\n",
      "Epoch 25/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7670 - loss: 1.1959 - val_accuracy: 0.8055 - val_loss: 0.5079\n",
      "Epoch 26/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7923 - loss: 0.5293 - val_accuracy: 0.8055 - val_loss: 0.4926\n",
      "Epoch 27/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.5040 - val_accuracy: 0.8055 - val_loss: 0.4927\n",
      "Epoch 28/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7947 - loss: 0.5088 - val_accuracy: 0.8055 - val_loss: 0.4937\n",
      "Epoch 29/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7974 - loss: 0.5057 - val_accuracy: 0.8055 - val_loss: 0.5078\n",
      "Epoch 30/30\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.5051 - val_accuracy: 0.8055 - val_loss: 0.4966\n",
      "Test-Accuracy: 0.7940000295639038\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(15, activation = \"selu\"))\n",
    "\n",
    "model.add(layers.Dense(10, activation = \"selu\"))\n",
    "\n",
    "model.add(layers.Dense(10, activation = \"selu\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "results = model.fit(\n",
    " train_points, train_values,\n",
    " epochs= 30,\n",
    " batch_size = 10,\n",
    " validation_data = (test_points, test_values)\n",
    ")\n",
    "print(\"Test-Accuracy:\", np.max(results.history[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neural_networks.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, 'neural_networks.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
